{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T06:42:06.811585Z","iopub.status.busy":"2024-02-24T06:42:06.811240Z","iopub.status.idle":"2024-02-24T06:43:22.498694Z","shell.execute_reply":"2024-02-24T06:43:22.497819Z","shell.execute_reply.started":"2024-02-24T06:42:06.811555Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting py7zr\n","  Downloading py7zr-0.20.8-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\n","Collecting pycryptodomex>=3.16.0 (from py7zr)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting pyzstd>=0.15.9 (from py7zr)\n","  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n","Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n","  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n","Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n","  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting multivolumefile>=0.2.3 (from py7zr)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n","  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n","Collecting brotli>=1.1.0 (from py7zr)\n","  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n","Downloading py7zr-0.20.8-py3-none-any.whl (67 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n","  Attempting uninstall: brotli\n","    Found existing installation: Brotli 1.0.9\n","    Uninstalling Brotli-1.0.9:\n","      Successfully uninstalled Brotli-1.0.9\n","Successfully installed brotli-1.1.0 inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.20.8 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.15.9\n"]}],"source":["import numpy as np \n","import pandas as pd # for reading csv file\n","\n","#train and test images are .7z archives, we need to unpack them\n","!pip install py7zr\n","\n","from py7zr import unpack_7zarchive\n","import shutil\n","\n","#Before using, we need to register unpack format\n","shutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\n","\n","#unpack train images in /kaggle/working or /kaggle/temp\n","shutil.unpack_archive('/kaggle/input/cifar-10/train.7z', '/kaggle/temp/')"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T06:43:22.500701Z","iopub.status.busy":"2024-02-24T06:43:22.500319Z","iopub.status.idle":"2024-02-24T06:43:25.962235Z","shell.execute_reply":"2024-02-24T06:43:25.961430Z","shell.execute_reply.started":"2024-02-24T06:43:22.500678Z"},"trusted":true},"outputs":[],"source":["import torch\n","if torch.cuda.is_available():\n","    device=torch.device(type=\"cuda\", index=0)\n","else:\n","    device=torch.device(type=\"cpu\", index=0)            "]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T06:43:29.468222Z","iopub.status.busy":"2024-02-24T06:43:29.467552Z","iopub.status.idle":"2024-02-24T06:43:29.521755Z","shell.execute_reply":"2024-02-24T06:43:29.520476Z","shell.execute_reply.started":"2024-02-24T06:43:29.468187Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['frog' 'truck' 'deer' 'automobile' 'bird' 'horse' 'ship' 'cat' 'dog'\n"," 'airplane']\n","{'frog': 0, 'truck': 1, 'deer': 2, 'automobile': 3, 'bird': 4, 'horse': 5, 'ship': 6, 'cat': 7, 'dog': 8, 'airplane': 9}\n","{0: 'frog', 1: 'truck', 2: 'deer', 3: 'automobile', 4: 'bird', 5: 'horse', 6: 'ship', 7: 'cat', 8: 'dog', 9: 'airplane'}\n"]}],"source":["#first fetching the class names from trainLabels.csv\n","\n","train_labels=pd.read_csv(\"/kaggle/input/cifar-10/trainLabels.csv\", header='infer')\n","\n","#unique labels\n","classes=train_labels['label'].unique()\n","\n","#confirming\n","print(classes)\n","\n","#classnames to classids\n","name2num={}\n","i=0\n","for name in classes:\n","    name2num[name]=i\n","    i=i+1\n","print(name2num)\n","num2name={}\n","for i in range(len(classes)):\n","    num2name[i]=classes[i]\n","print(num2name)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T06:43:31.913046Z","iopub.status.busy":"2024-02-24T06:43:31.912706Z","iopub.status.idle":"2024-02-24T06:43:34.489862Z","shell.execute_reply":"2024-02-24T06:43:34.488840Z","shell.execute_reply.started":"2024-02-24T06:43:31.913019Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import os\n","from torchvision.io import read_image\n","from torchvision.transforms import ToTensor, Normalize, Resize, Compose\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, imgpath, labelpath):\n","        super().__init__()\n","        self.imgpath=imgpath\n","        self.labelpath=labelpath\n","        self.labels=pd.read_csv(labelpath, header='infer')\n","        self.transform=Compose([Resize((224,224), antialias=True), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n","        \n","    def __len__(self):\n","        return self.labels.shape[0]\n","    \n","    def __getitem__(self,idx):\n","        finalpath=os.path.join(self.imgpath,str(idx+1))+'.png'\n","        img=read_image(finalpath)/255\n","        img=self.transform(img)\n","        label=self.labels.iloc[idx,1]\n","        label=name2num[label]\n","        return img,label\n","\n","traindataset=TrainDataset('/kaggle/temp/train','/kaggle/input/cifar-10/trainLabels.csv')        \n","        \n","batch_size=64    \n","traindataloader=DataLoader(dataset=traindataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-01T08:51:23.375212Z","iopub.status.busy":"2024-03-01T08:51:23.374868Z","iopub.status.idle":"2024-03-01T08:51:23.382127Z","shell.execute_reply":"2024-03-01T08:51:23.381213Z","shell.execute_reply.started":"2024-03-01T08:51:23.375186Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","from torchvision.models import resnet101, ResNet101_Weights\n","class Cifar10Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.pretrainednet=ResNet101(weights=ResNet101_Weights.DEFAULT)\n","        self.pretrainednet.classifier=nn.Sequential(\n","            nn.Linear(in_features=960, out_features=1280, \n","                   bias=True),nn.Hardswish(), \n","            nn.Dropout(p=0.2, inplace=True), \n","            nn.Linear(in_features=1280, out_features=10, \n","                      bias=True)\n","        )\n","        \n","    def forward(self,x):\n","        x=self.pretrainednet(x)\n","        return x"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T06:43:35.950532Z","iopub.status.busy":"2024-02-24T06:43:35.949710Z","iopub.status.idle":"2024-02-24T06:43:35.961479Z","shell.execute_reply":"2024-02-24T06:43:35.960329Z","shell.execute_reply.started":"2024-02-24T06:43:35.950494Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(dataloader, model,loss_fn, optimizer):\n","    model.train()\n","    track_loss=0\n","    num_correct=0\n","    num_param=0\n","    \n","    for i, (imgs, labels) in enumerate(dataloader):\n","        imgs=imgs.to(device)\n","        labels=labels.to(device)\n","        pred=model(imgs)\n","                    \n","        loss=loss_fn(pred,labels)\n","        track_loss+=loss.item()\n","        num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n","        \n","        running_loss=round(track_loss/(i+(imgs.shape[0]/batch_size)),2)\n","        running_acc=round((num_correct/((i*batch_size+imgs.shape[0])))*100,2)\n","        \n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if i%100==0:\n","            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n","            \n","    epoch_loss=running_loss\n","    epoch_acc=running_acc\n","    return epoch_loss, epoch_acc"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T16:09:37.132658Z","iopub.status.busy":"2024-02-23T16:09:37.132296Z","iopub.status.idle":"2024-02-23T16:40:49.920295Z","shell.execute_reply":"2024-02-23T16:40:49.919344Z","shell.execute_reply.started":"2024-02-23T16:09:37.132629Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n","100%|██████████| 21.1M/21.1M [00:00<00:00, 67.1MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch No: 1\n","Batch: 1 / 782 Running Loss: 2.3 Running Accuracy: 14.06\n","Batch: 101 / 782 Running Loss: 1.06 Running Accuracy: 63.81\n","Batch: 201 / 782 Running Loss: 0.92 Running Accuracy: 67.96\n","Batch: 301 / 782 Running Loss: 0.87 Running Accuracy: 69.68\n","Batch: 401 / 782 Running Loss: 0.84 Running Accuracy: 70.96\n","Batch: 501 / 782 Running Loss: 0.81 Running Accuracy: 71.55\n","Batch: 601 / 782 Running Loss: 0.8 Running Accuracy: 72.02\n","Batch: 701 / 782 Running Loss: 0.79 Running Accuracy: 72.45\n","Training: Epoch Loss: 0.78 Epoch Accuracy: 72.84\n","--------------------------------------------------\n","Epoch No: 2\n","Batch: 1 / 782 Running Loss: 0.62 Running Accuracy: 78.12\n","Batch: 101 / 782 Running Loss: 0.67 Running Accuracy: 76.5\n","Batch: 201 / 782 Running Loss: 0.64 Running Accuracy: 77.07\n","Batch: 301 / 782 Running Loss: 0.64 Running Accuracy: 77.35\n","Batch: 401 / 782 Running Loss: 0.64 Running Accuracy: 77.5\n","Batch: 501 / 782 Running Loss: 0.64 Running Accuracy: 77.55\n","Batch: 601 / 782 Running Loss: 0.64 Running Accuracy: 77.51\n","Batch: 701 / 782 Running Loss: 0.63 Running Accuracy: 77.64\n","Training: Epoch Loss: 0.63 Epoch Accuracy: 77.79\n","--------------------------------------------------\n","Epoch No: 3\n","Batch: 1 / 782 Running Loss: 0.58 Running Accuracy: 79.69\n","Batch: 101 / 782 Running Loss: 0.59 Running Accuracy: 79.38\n","Batch: 201 / 782 Running Loss: 0.57 Running Accuracy: 79.77\n","Batch: 301 / 782 Running Loss: 0.56 Running Accuracy: 80.08\n","Batch: 401 / 782 Running Loss: 0.56 Running Accuracy: 80.21\n","Batch: 501 / 782 Running Loss: 0.56 Running Accuracy: 80.29\n","Batch: 601 / 782 Running Loss: 0.56 Running Accuracy: 80.29\n","Batch: 701 / 782 Running Loss: 0.56 Running Accuracy: 80.36\n","Training: Epoch Loss: 0.55 Epoch Accuracy: 80.51\n","--------------------------------------------------\n","Epoch No: 4\n","Batch: 1 / 782 Running Loss: 0.49 Running Accuracy: 81.25\n","Batch: 101 / 782 Running Loss: 0.52 Running Accuracy: 81.81\n","Batch: 201 / 782 Running Loss: 0.5 Running Accuracy: 82.21\n","Batch: 301 / 782 Running Loss: 0.49 Running Accuracy: 82.63\n","Batch: 401 / 782 Running Loss: 0.49 Running Accuracy: 82.73\n","Batch: 501 / 782 Running Loss: 0.49 Running Accuracy: 82.86\n","Batch: 601 / 782 Running Loss: 0.48 Running Accuracy: 82.94\n","Batch: 701 / 782 Running Loss: 0.48 Running Accuracy: 83.07\n","Training: Epoch Loss: 0.47 Epoch Accuracy: 83.31\n","--------------------------------------------------\n","Epoch No: 5\n","Batch: 1 / 782 Running Loss: 0.39 Running Accuracy: 84.38\n","Batch: 101 / 782 Running Loss: 0.42 Running Accuracy: 85.07\n","Batch: 201 / 782 Running Loss: 0.41 Running Accuracy: 85.29\n","Batch: 301 / 782 Running Loss: 0.41 Running Accuracy: 85.71\n","Batch: 401 / 782 Running Loss: 0.4 Running Accuracy: 85.76\n","Batch: 501 / 782 Running Loss: 0.4 Running Accuracy: 85.94\n","Batch: 601 / 782 Running Loss: 0.4 Running Accuracy: 86.06\n","Batch: 701 / 782 Running Loss: 0.39 Running Accuracy: 86.24\n","Training: Epoch Loss: 0.39 Epoch Accuracy: 86.39\n","--------------------------------------------------\n","Epoch No: 6\n","Batch: 1 / 782 Running Loss: 0.29 Running Accuracy: 87.5\n","Batch: 101 / 782 Running Loss: 0.34 Running Accuracy: 88.12\n","Batch: 201 / 782 Running Loss: 0.33 Running Accuracy: 88.18\n","Batch: 301 / 782 Running Loss: 0.32 Running Accuracy: 88.53\n","Batch: 401 / 782 Running Loss: 0.32 Running Accuracy: 88.67\n","Batch: 501 / 782 Running Loss: 0.32 Running Accuracy: 88.91\n","Batch: 601 / 782 Running Loss: 0.31 Running Accuracy: 89.05\n","Batch: 701 / 782 Running Loss: 0.31 Running Accuracy: 89.19\n","Training: Epoch Loss: 0.3 Epoch Accuracy: 89.3\n","--------------------------------------------------\n","Epoch No: 7\n","Batch: 1 / 782 Running Loss: 0.23 Running Accuracy: 90.62\n","Batch: 101 / 782 Running Loss: 0.26 Running Accuracy: 91.01\n","Batch: 201 / 782 Running Loss: 0.24 Running Accuracy: 91.45\n","Batch: 301 / 782 Running Loss: 0.24 Running Accuracy: 91.68\n","Batch: 401 / 782 Running Loss: 0.24 Running Accuracy: 91.75\n","Batch: 501 / 782 Running Loss: 0.24 Running Accuracy: 91.86\n","Batch: 601 / 782 Running Loss: 0.23 Running Accuracy: 91.92\n","Batch: 701 / 782 Running Loss: 0.23 Running Accuracy: 92.04\n","Training: Epoch Loss: 0.23 Epoch Accuracy: 92.11\n","--------------------------------------------------\n","Epoch No: 8\n","Batch: 1 / 782 Running Loss: 0.14 Running Accuracy: 96.88\n","Batch: 101 / 782 Running Loss: 0.19 Running Accuracy: 93.72\n","Batch: 201 / 782 Running Loss: 0.19 Running Accuracy: 93.42\n","Batch: 301 / 782 Running Loss: 0.18 Running Accuracy: 93.58\n","Batch: 401 / 782 Running Loss: 0.18 Running Accuracy: 93.66\n","Batch: 501 / 782 Running Loss: 0.18 Running Accuracy: 93.63\n","Batch: 601 / 782 Running Loss: 0.18 Running Accuracy: 93.74\n","Batch: 701 / 782 Running Loss: 0.17 Running Accuracy: 93.84\n","Training: Epoch Loss: 0.17 Epoch Accuracy: 93.82\n","--------------------------------------------------\n","Epoch No: 9\n","Batch: 1 / 782 Running Loss: 0.18 Running Accuracy: 90.62\n","Batch: 101 / 782 Running Loss: 0.15 Running Accuracy: 94.74\n","Batch: 201 / 782 Running Loss: 0.15 Running Accuracy: 94.78\n","Batch: 301 / 782 Running Loss: 0.14 Running Accuracy: 94.87\n","Batch: 401 / 782 Running Loss: 0.14 Running Accuracy: 95.01\n","Batch: 501 / 782 Running Loss: 0.14 Running Accuracy: 94.99\n","Batch: 601 / 782 Running Loss: 0.14 Running Accuracy: 95.16\n","Batch: 701 / 782 Running Loss: 0.14 Running Accuracy: 95.25\n","Training: Epoch Loss: 0.14 Epoch Accuracy: 95.16\n","--------------------------------------------------\n","Epoch No: 10\n","Batch: 1 / 782 Running Loss: 0.11 Running Accuracy: 98.44\n","Batch: 101 / 782 Running Loss: 0.12 Running Accuracy: 95.67\n","Batch: 201 / 782 Running Loss: 0.13 Running Accuracy: 95.44\n","Batch: 301 / 782 Running Loss: 0.12 Running Accuracy: 95.55\n","Batch: 401 / 782 Running Loss: 0.12 Running Accuracy: 95.75\n","Batch: 501 / 782 Running Loss: 0.12 Running Accuracy: 95.77\n","Batch: 601 / 782 Running Loss: 0.12 Running Accuracy: 95.79\n","Batch: 701 / 782 Running Loss: 0.12 Running Accuracy: 95.87\n","Training: Epoch Loss: 0.12 Epoch Accuracy: 95.84\n","--------------------------------------------------\n","Epoch No: 1\n","Batch: 1 / 782 Running Loss: 0.13 Running Accuracy: 95.31\n","Batch: 101 / 782 Running Loss: 0.8 Running Accuracy: 77.66\n","Batch: 201 / 782 Running Loss: 0.67 Running Accuracy: 80.46\n","Batch: 301 / 782 Running Loss: 0.59 Running Accuracy: 82.4\n","Batch: 401 / 782 Running Loss: 0.54 Running Accuracy: 83.66\n","Batch: 501 / 782 Running Loss: 0.51 Running Accuracy: 84.61\n","Batch: 601 / 782 Running Loss: 0.48 Running Accuracy: 85.21\n","Batch: 701 / 782 Running Loss: 0.46 Running Accuracy: 85.94\n","Training: Epoch Loss: 0.44 Epoch Accuracy: 86.4\n","--------------------------------------------------\n","Epoch No: 2\n","Batch: 1 / 782 Running Loss: 0.1 Running Accuracy: 95.31\n","Batch: 101 / 782 Running Loss: 0.23 Running Accuracy: 92.47\n","Batch: 201 / 782 Running Loss: 0.24 Running Accuracy: 92.41\n","Batch: 301 / 782 Running Loss: 0.23 Running Accuracy: 92.45\n","Batch: 401 / 782 Running Loss: 0.22 Running Accuracy: 92.78\n","Batch: 501 / 782 Running Loss: 0.21 Running Accuracy: 93.01\n","Batch: 601 / 782 Running Loss: 0.21 Running Accuracy: 93.07\n","Batch: 701 / 782 Running Loss: 0.21 Running Accuracy: 93.11\n","Training: Epoch Loss: 0.21 Epoch Accuracy: 93.08\n","--------------------------------------------------\n","Epoch No: 3\n","Batch: 1 / 782 Running Loss: 0.18 Running Accuracy: 95.31\n","Batch: 101 / 782 Running Loss: 0.18 Running Accuracy: 93.8\n","Batch: 201 / 782 Running Loss: 0.17 Running Accuracy: 94.13\n","Batch: 301 / 782 Running Loss: 0.17 Running Accuracy: 94.34\n","Batch: 401 / 782 Running Loss: 0.16 Running Accuracy: 94.62\n","Batch: 501 / 782 Running Loss: 0.16 Running Accuracy: 94.68\n","Batch: 601 / 782 Running Loss: 0.16 Running Accuracy: 94.68\n","Batch: 701 / 782 Running Loss: 0.16 Running Accuracy: 94.7\n","Training: Epoch Loss: 0.15 Epoch Accuracy: 94.77\n","--------------------------------------------------\n","Epoch No: 4\n","Batch: 1 / 782 Running Loss: 0.08 Running Accuracy: 98.44\n","Batch: 101 / 782 Running Loss: 0.14 Running Accuracy: 95.13\n","Batch: 201 / 782 Running Loss: 0.14 Running Accuracy: 95.14\n","Batch: 301 / 782 Running Loss: 0.14 Running Accuracy: 95.08\n","Batch: 401 / 782 Running Loss: 0.14 Running Accuracy: 95.17\n","Batch: 501 / 782 Running Loss: 0.14 Running Accuracy: 95.2\n","Batch: 601 / 782 Running Loss: 0.14 Running Accuracy: 95.24\n","Batch: 701 / 782 Running Loss: 0.14 Running Accuracy: 95.29\n","Training: Epoch Loss: 0.14 Epoch Accuracy: 95.38\n","--------------------------------------------------\n","Epoch No: 5\n","Batch: 1 / 782 Running Loss: 0.1 Running Accuracy: 96.88\n","Batch: 101 / 782 Running Loss: 0.11 Running Accuracy: 96.15\n","Batch: 201 / 782 Running Loss: 0.13 Running Accuracy: 95.72\n","Batch: 301 / 782 Running Loss: 0.12 Running Accuracy: 95.86\n","Batch: 401 / 782 Running Loss: 0.12 Running Accuracy: 95.94\n","Batch: 501 / 782 Running Loss: 0.11 Running Accuracy: 96.01\n","Batch: 601 / 782 Running Loss: 0.12 Running Accuracy: 95.97\n","Batch: 701 / 782 Running Loss: 0.11 Running Accuracy: 96.07\n","Training: Epoch Loss: 0.11 Epoch Accuracy: 96.1\n","--------------------------------------------------\n","Epoch No: 6\n","Batch: 1 / 782 Running Loss: 0.07 Running Accuracy: 96.88\n","Batch: 101 / 782 Running Loss: 0.1 Running Accuracy: 96.36\n","Batch: 201 / 782 Running Loss: 0.11 Running Accuracy: 96.18\n","Batch: 301 / 782 Running Loss: 0.11 Running Accuracy: 96.26\n","Batch: 401 / 782 Running Loss: 0.1 Running Accuracy: 96.31\n","Batch: 501 / 782 Running Loss: 0.1 Running Accuracy: 96.34\n","Batch: 601 / 782 Running Loss: 0.11 Running Accuracy: 96.36\n","Batch: 701 / 782 Running Loss: 0.11 Running Accuracy: 96.36\n","Training: Epoch Loss: 0.11 Epoch Accuracy: 96.35\n","--------------------------------------------------\n","Epoch No: 7\n","Batch: 1 / 782 Running Loss: 0.03 Running Accuracy: 100.0\n","Batch: 101 / 782 Running Loss: 0.08 Running Accuracy: 97.35\n","Batch: 201 / 782 Running Loss: 0.09 Running Accuracy: 97.05\n","Batch: 301 / 782 Running Loss: 0.1 Running Accuracy: 96.82\n","Batch: 401 / 782 Running Loss: 0.1 Running Accuracy: 96.78\n","Batch: 501 / 782 Running Loss: 0.09 Running Accuracy: 96.8\n","Batch: 601 / 782 Running Loss: 0.09 Running Accuracy: 96.84\n","Batch: 701 / 782 Running Loss: 0.09 Running Accuracy: 96.81\n","Training: Epoch Loss: 0.09 Epoch Accuracy: 96.79\n","--------------------------------------------------\n","Epoch No: 8\n","Batch: 1 / 782 Running Loss: 0.09 Running Accuracy: 96.88\n","Batch: 101 / 782 Running Loss: 0.1 Running Accuracy: 96.38\n","Batch: 201 / 782 Running Loss: 0.1 Running Accuracy: 96.6\n","Batch: 301 / 782 Running Loss: 0.1 Running Accuracy: 96.5\n","Batch: 401 / 782 Running Loss: 0.09 Running Accuracy: 96.72\n","Batch: 501 / 782 Running Loss: 0.09 Running Accuracy: 96.92\n","Batch: 601 / 782 Running Loss: 0.09 Running Accuracy: 97.08\n","Batch: 701 / 782 Running Loss: 0.08 Running Accuracy: 97.18\n","Training: Epoch Loss: 0.08 Epoch Accuracy: 97.18\n","--------------------------------------------------\n","Epoch No: 9\n","Batch: 1 / 782 Running Loss: 0.01 Running Accuracy: 100.0\n","Batch: 101 / 782 Running Loss: 0.06 Running Accuracy: 97.65\n","Batch: 201 / 782 Running Loss: 0.08 Running Accuracy: 97.17\n","Batch: 301 / 782 Running Loss: 0.08 Running Accuracy: 97.1\n","Batch: 401 / 782 Running Loss: 0.08 Running Accuracy: 97.13\n","Batch: 501 / 782 Running Loss: 0.08 Running Accuracy: 97.2\n","Batch: 601 / 782 Running Loss: 0.08 Running Accuracy: 97.26\n","Batch: 701 / 782 Running Loss: 0.08 Running Accuracy: 97.25\n","Training: Epoch Loss: 0.08 Epoch Accuracy: 97.25\n","--------------------------------------------------\n","Epoch No: 10\n","Batch: 1 / 782 Running Loss: 0.02 Running Accuracy: 100.0\n","Batch: 101 / 782 Running Loss: 0.08 Running Accuracy: 97.42\n","Batch: 201 / 782 Running Loss: 0.08 Running Accuracy: 97.44\n","Batch: 301 / 782 Running Loss: 0.07 Running Accuracy: 97.54\n","Batch: 401 / 782 Running Loss: 0.07 Running Accuracy: 97.69\n","Batch: 501 / 782 Running Loss: 0.07 Running Accuracy: 97.72\n","Batch: 601 / 782 Running Loss: 0.07 Running Accuracy: 97.76\n","Batch: 701 / 782 Running Loss: 0.07 Running Accuracy: 97.77\n","Training: Epoch Loss: 0.07 Epoch Accuracy: 97.78\n","--------------------------------------------------\n"]}],"source":["model=Cifar10Net()\n","model=model.to(device)\n","\n","for param in model.pretrainednet.features.parameters():\n","    param.requires_grad=False\n","\n","loss_fn=nn.CrossEntropyLoss()\n","lr=0.001\n","#optimizer=torch.optim.SGD(params=model.parameters(), lr=lr)\n","optimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\n","n_epochs=10\n","\n","for i in range(n_epochs):\n","    print(\"Epoch No:\",i+1)\n","    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,model,loss_fn,optimizer)\n","    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n","    print(\"--------------------------------------------------\")\n","\n","for param in model.pretrainednet.features.parameters():\n","    param.requires_grad=True\n","\n","for i in range(n_epochs):\n","    print(\"Epoch No:\",i+1)\n","    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,model,loss_fn,optimizer)\n","    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n","    print(\"--------------------------------------------------\")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T06:43:44.256723Z","iopub.status.busy":"2024-02-24T06:43:44.256345Z","iopub.status.idle":"2024-02-24T06:43:44.264132Z","shell.execute_reply":"2024-02-24T06:43:44.263113Z","shell.execute_reply.started":"2024-02-24T06:43:44.256693Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","from torchvision.models.alexnet import AlexNet,AlexNet_Weights\n","\n","class Cifar10Net_using_AlexNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.pretrainednet=AlexNet()\n","        self.pretrainednet.classifier=nn.Sequential(\n","            nn.Linear(in_features=9216, out_features=4096, \n","                   bias=True),\n","            nn.Hardswish(), \n","            nn.Dropout(p=0.2, inplace=True),\n","            nn.Linear(in_features = 4096, out_features = 1280),\n","            nn.ReLU(),\n","            nn.Linear(in_features=1280, out_features=10, \n","                      bias=True)\n","        )\n","        \n","    def forward(self,x):\n","        x=self.pretrainednet(x)\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-23T16:44:19.190414Z","iopub.status.busy":"2024-02-23T16:44:19.189712Z","iopub.status.idle":"2024-02-23T16:44:19.194718Z","shell.execute_reply":"2024-02-23T16:44:19.193801Z","shell.execute_reply.started":"2024-02-23T16:44:19.190383Z"},"trusted":true},"outputs":[],"source":["# import torch.nn as nn\n","# from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n","# class Cifar10Net(nn.Module):\n","#     def __init__(self):\n","#         super().__init__()\n","#         self.pretrainednet=mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n","#         self.pretrainednet.classifier=nn.Sequential(\n","#             nn.Linear(in_features=960, out_features=1280, \n","#                    bias=True),nn.Hardswish(), \n","#             nn.Dropout(p=0.2, inplace=True), \n","#             nn.Linear(in_features=1280, out_features=10, \n","#                       bias=True)\n","#         )\n","        \n","#     def forward(self,x):\n","#         x=self.pretrainednet(x)\n","#         return x"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T07:13:02.756418Z","iopub.status.busy":"2024-02-24T07:13:02.756017Z","iopub.status.idle":"2024-02-24T07:42:50.044931Z","shell.execute_reply":"2024-02-24T07:42:50.043992Z","shell.execute_reply.started":"2024-02-24T07:13:02.756388Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch No: 1\n","Batch: 1 / 782 Running Loss: 2.3 Running Accuracy: 3.12\n","Batch: 101 / 782 Running Loss: 2.0 Running Accuracy: 25.08\n","Batch: 201 / 782 Running Loss: 1.87 Running Accuracy: 30.26\n","Batch: 301 / 782 Running Loss: 1.8 Running Accuracy: 33.22\n","Batch: 401 / 782 Running Loss: 1.74 Running Accuracy: 35.23\n","Batch: 501 / 782 Running Loss: 1.7 Running Accuracy: 36.83\n","Batch: 601 / 782 Running Loss: 1.67 Running Accuracy: 38.13\n","Batch: 701 / 782 Running Loss: 1.64 Running Accuracy: 39.06\n","Training: Epoch Loss: 1.63 Epoch Accuracy: 39.83\n","--------------------------------------------------\n","Epoch No: 2\n","Batch: 1 / 782 Running Loss: 1.64 Running Accuracy: 43.75\n","Batch: 101 / 782 Running Loss: 1.44 Running Accuracy: 46.32\n","Batch: 201 / 782 Running Loss: 1.44 Running Accuracy: 47.15\n","Batch: 301 / 782 Running Loss: 1.43 Running Accuracy: 47.5\n","Batch: 401 / 782 Running Loss: 1.41 Running Accuracy: 47.95\n","Batch: 501 / 782 Running Loss: 1.4 Running Accuracy: 48.44\n","Batch: 601 / 782 Running Loss: 1.4 Running Accuracy: 48.68\n","Batch: 701 / 782 Running Loss: 1.39 Running Accuracy: 48.85\n","Training: Epoch Loss: 1.39 Epoch Accuracy: 49.11\n","--------------------------------------------------\n","Epoch No: 3\n","Batch: 1 / 782 Running Loss: 1.71 Running Accuracy: 39.06\n","Batch: 101 / 782 Running Loss: 1.33 Running Accuracy: 52.15\n","Batch: 201 / 782 Running Loss: 1.33 Running Accuracy: 51.86\n","Batch: 301 / 782 Running Loss: 1.33 Running Accuracy: 51.9\n","Batch: 401 / 782 Running Loss: 1.32 Running Accuracy: 52.21\n","Batch: 501 / 782 Running Loss: 1.31 Running Accuracy: 52.35\n","Batch: 601 / 782 Running Loss: 1.31 Running Accuracy: 52.41\n","Batch: 701 / 782 Running Loss: 1.31 Running Accuracy: 52.41\n","Training: Epoch Loss: 1.3 Epoch Accuracy: 52.59\n","--------------------------------------------------\n","Epoch No: 4\n","Batch: 1 / 782 Running Loss: 1.62 Running Accuracy: 45.31\n","Batch: 101 / 782 Running Loss: 1.28 Running Accuracy: 53.34\n","Batch: 201 / 782 Running Loss: 1.27 Running Accuracy: 54.05\n","Batch: 301 / 782 Running Loss: 1.26 Running Accuracy: 54.29\n","Batch: 401 / 782 Running Loss: 1.25 Running Accuracy: 54.54\n","Batch: 501 / 782 Running Loss: 1.25 Running Accuracy: 54.56\n","Batch: 601 / 782 Running Loss: 1.25 Running Accuracy: 54.71\n","Batch: 701 / 782 Running Loss: 1.25 Running Accuracy: 54.71\n","Training: Epoch Loss: 1.24 Epoch Accuracy: 54.86\n","--------------------------------------------------\n","Epoch No: 5\n","Batch: 1 / 782 Running Loss: 1.66 Running Accuracy: 46.88\n","Batch: 101 / 782 Running Loss: 1.2 Running Accuracy: 56.85\n","Batch: 201 / 782 Running Loss: 1.21 Running Accuracy: 57.0\n","Batch: 301 / 782 Running Loss: 1.2 Running Accuracy: 57.08\n","Batch: 401 / 782 Running Loss: 1.2 Running Accuracy: 57.08\n","Batch: 501 / 782 Running Loss: 1.2 Running Accuracy: 56.92\n","Batch: 601 / 782 Running Loss: 1.2 Running Accuracy: 56.92\n","Batch: 701 / 782 Running Loss: 1.2 Running Accuracy: 56.9\n","Training: Epoch Loss: 1.19 Epoch Accuracy: 56.97\n","--------------------------------------------------\n","Epoch No: 6\n","Batch: 1 / 782 Running Loss: 1.4 Running Accuracy: 56.25\n","Batch: 101 / 782 Running Loss: 1.15 Running Accuracy: 58.62\n","Batch: 201 / 782 Running Loss: 1.16 Running Accuracy: 58.31\n","Batch: 301 / 782 Running Loss: 1.16 Running Accuracy: 58.23\n","Batch: 401 / 782 Running Loss: 1.15 Running Accuracy: 58.47\n","Batch: 501 / 782 Running Loss: 1.16 Running Accuracy: 58.26\n","Batch: 601 / 782 Running Loss: 1.16 Running Accuracy: 58.18\n","Batch: 701 / 782 Running Loss: 1.16 Running Accuracy: 58.2\n","Training: Epoch Loss: 1.16 Epoch Accuracy: 58.4\n","--------------------------------------------------\n","Epoch No: 7\n","Batch: 1 / 782 Running Loss: 1.25 Running Accuracy: 59.38\n","Batch: 101 / 782 Running Loss: 1.11 Running Accuracy: 59.59\n","Batch: 201 / 782 Running Loss: 1.13 Running Accuracy: 59.5\n","Batch: 301 / 782 Running Loss: 1.14 Running Accuracy: 59.25\n","Batch: 401 / 782 Running Loss: 1.13 Running Accuracy: 59.41\n","Batch: 501 / 782 Running Loss: 1.13 Running Accuracy: 59.35\n","Batch: 601 / 782 Running Loss: 1.13 Running Accuracy: 59.23\n","Batch: 701 / 782 Running Loss: 1.13 Running Accuracy: 59.16\n","Training: Epoch Loss: 1.13 Epoch Accuracy: 59.34\n","--------------------------------------------------\n","Epoch No: 8\n","Batch: 1 / 782 Running Loss: 1.17 Running Accuracy: 62.5\n","Batch: 101 / 782 Running Loss: 1.08 Running Accuracy: 61.54\n","Batch: 201 / 782 Running Loss: 1.1 Running Accuracy: 60.82\n","Batch: 301 / 782 Running Loss: 1.1 Running Accuracy: 60.65\n","Batch: 401 / 782 Running Loss: 1.1 Running Accuracy: 60.67\n","Batch: 501 / 782 Running Loss: 1.1 Running Accuracy: 60.68\n","Batch: 601 / 782 Running Loss: 1.1 Running Accuracy: 60.51\n","Batch: 701 / 782 Running Loss: 1.11 Running Accuracy: 60.43\n","Training: Epoch Loss: 1.1 Epoch Accuracy: 60.53\n","--------------------------------------------------\n","Epoch No: 9\n","Batch: 1 / 782 Running Loss: 1.12 Running Accuracy: 64.06\n","Batch: 101 / 782 Running Loss: 1.05 Running Accuracy: 62.9\n","Batch: 201 / 782 Running Loss: 1.08 Running Accuracy: 62.13\n","Batch: 301 / 782 Running Loss: 1.08 Running Accuracy: 62.17\n","Batch: 401 / 782 Running Loss: 1.07 Running Accuracy: 62.14\n","Batch: 501 / 782 Running Loss: 1.07 Running Accuracy: 62.03\n","Batch: 601 / 782 Running Loss: 1.07 Running Accuracy: 61.71\n","Batch: 701 / 782 Running Loss: 1.08 Running Accuracy: 61.63\n","Training: Epoch Loss: 1.07 Epoch Accuracy: 61.74\n","--------------------------------------------------\n","Epoch No: 10\n","Batch: 1 / 782 Running Loss: 1.12 Running Accuracy: 62.5\n","Batch: 101 / 782 Running Loss: 1.02 Running Accuracy: 63.38\n","Batch: 201 / 782 Running Loss: 1.04 Running Accuracy: 62.83\n","Batch: 301 / 782 Running Loss: 1.05 Running Accuracy: 62.76\n","Batch: 401 / 782 Running Loss: 1.05 Running Accuracy: 62.66\n","Batch: 501 / 782 Running Loss: 1.05 Running Accuracy: 62.72\n","Batch: 601 / 782 Running Loss: 1.05 Running Accuracy: 62.65\n","Batch: 701 / 782 Running Loss: 1.05 Running Accuracy: 62.59\n","Training: Epoch Loss: 1.04 Epoch Accuracy: 62.78\n","--------------------------------------------------\n","Epoch No: 1\n","Batch: 1 / 782 Running Loss: 1.1 Running Accuracy: 64.06\n","Batch: 101 / 782 Running Loss: 69.72 Running Accuracy: 11.06\n","Batch: 201 / 782 Running Loss: 36.17 Running Accuracy: 11.59\n","Batch: 301 / 782 Running Loss: 24.88 Running Accuracy: 13.19\n","Batch: 401 / 782 Running Loss: 19.17 Running Accuracy: 16.04\n","Batch: 501 / 782 Running Loss: 15.72 Running Accuracy: 18.24\n","Batch: 601 / 782 Running Loss: 13.42 Running Accuracy: 20.14\n","Batch: 701 / 782 Running Loss: 11.76 Running Accuracy: 22.0\n","Training: Epoch Loss: 10.74 Epoch Accuracy: 23.36\n","--------------------------------------------------\n","Epoch No: 2\n","Batch: 1 / 782 Running Loss: 1.92 Running Accuracy: 34.38\n","Batch: 101 / 782 Running Loss: 1.68 Running Accuracy: 37.9\n","Batch: 201 / 782 Running Loss: 1.66 Running Accuracy: 38.25\n","Batch: 301 / 782 Running Loss: 1.65 Running Accuracy: 38.94\n","Batch: 401 / 782 Running Loss: 1.63 Running Accuracy: 39.99\n","Batch: 501 / 782 Running Loss: 1.61 Running Accuracy: 40.74\n","Batch: 601 / 782 Running Loss: 1.6 Running Accuracy: 40.97\n","Batch: 701 / 782 Running Loss: 1.59 Running Accuracy: 41.53\n","Training: Epoch Loss: 1.58 Epoch Accuracy: 42.03\n","--------------------------------------------------\n","Epoch No: 3\n","Batch: 1 / 782 Running Loss: 1.54 Running Accuracy: 48.44\n","Batch: 101 / 782 Running Loss: 1.46 Running Accuracy: 46.98\n","Batch: 201 / 782 Running Loss: 1.45 Running Accuracy: 47.63\n","Batch: 301 / 782 Running Loss: 1.44 Running Accuracy: 47.91\n","Batch: 401 / 782 Running Loss: 1.42 Running Accuracy: 48.4\n","Batch: 501 / 782 Running Loss: 1.41 Running Accuracy: 48.76\n","Batch: 601 / 782 Running Loss: 1.41 Running Accuracy: 48.91\n","Batch: 701 / 782 Running Loss: 1.4 Running Accuracy: 49.19\n","Training: Epoch Loss: 1.39 Epoch Accuracy: 49.62\n","--------------------------------------------------\n","Epoch No: 4\n","Batch: 1 / 782 Running Loss: 1.23 Running Accuracy: 60.94\n","Batch: 101 / 782 Running Loss: 1.3 Running Accuracy: 53.37\n","Batch: 201 / 782 Running Loss: 1.29 Running Accuracy: 53.73\n","Batch: 301 / 782 Running Loss: 1.29 Running Accuracy: 53.93\n","Batch: 401 / 782 Running Loss: 1.27 Running Accuracy: 54.14\n","Batch: 501 / 782 Running Loss: 1.26 Running Accuracy: 54.5\n","Batch: 601 / 782 Running Loss: 1.26 Running Accuracy: 54.51\n","Batch: 701 / 782 Running Loss: 1.25 Running Accuracy: 54.73\n","Training: Epoch Loss: 1.25 Epoch Accuracy: 55.07\n","--------------------------------------------------\n","Epoch No: 5\n","Batch: 1 / 782 Running Loss: 1.21 Running Accuracy: 62.5\n","Batch: 101 / 782 Running Loss: 1.17 Running Accuracy: 58.9\n","Batch: 201 / 782 Running Loss: 1.15 Running Accuracy: 59.35\n","Batch: 301 / 782 Running Loss: 1.15 Running Accuracy: 59.4\n","Batch: 401 / 782 Running Loss: 1.14 Running Accuracy: 59.5\n","Batch: 501 / 782 Running Loss: 1.13 Running Accuracy: 59.96\n","Batch: 601 / 782 Running Loss: 1.13 Running Accuracy: 59.8\n","Batch: 701 / 782 Running Loss: 1.12 Running Accuracy: 60.05\n","Training: Epoch Loss: 1.11 Epoch Accuracy: 60.26\n","--------------------------------------------------\n","Epoch No: 6\n","Batch: 1 / 782 Running Loss: 1.01 Running Accuracy: 68.75\n","Batch: 101 / 782 Running Loss: 1.01 Running Accuracy: 64.02\n","Batch: 201 / 782 Running Loss: 1.01 Running Accuracy: 64.13\n","Batch: 301 / 782 Running Loss: 1.03 Running Accuracy: 63.38\n","Batch: 401 / 782 Running Loss: 1.02 Running Accuracy: 63.59\n","Batch: 501 / 782 Running Loss: 1.01 Running Accuracy: 64.12\n","Batch: 601 / 782 Running Loss: 1.01 Running Accuracy: 64.15\n","Batch: 701 / 782 Running Loss: 1.0 Running Accuracy: 64.48\n","Training: Epoch Loss: 0.99 Epoch Accuracy: 64.8\n","--------------------------------------------------\n","Epoch No: 7\n","Batch: 1 / 782 Running Loss: 0.78 Running Accuracy: 75.0\n","Batch: 101 / 782 Running Loss: 0.89 Running Accuracy: 68.39\n","Batch: 201 / 782 Running Loss: 0.9 Running Accuracy: 68.13\n","Batch: 301 / 782 Running Loss: 0.92 Running Accuracy: 67.77\n","Batch: 401 / 782 Running Loss: 0.89 Running Accuracy: 68.52\n","Batch: 501 / 782 Running Loss: 0.88 Running Accuracy: 69.12\n","Batch: 601 / 782 Running Loss: 0.87 Running Accuracy: 69.31\n","Batch: 701 / 782 Running Loss: 0.86 Running Accuracy: 69.76\n","Training: Epoch Loss: 0.85 Epoch Accuracy: 70.2\n","--------------------------------------------------\n","Epoch No: 8\n","Batch: 1 / 782 Running Loss: 0.78 Running Accuracy: 78.12\n","Batch: 101 / 782 Running Loss: 0.73 Running Accuracy: 74.24\n","Batch: 201 / 782 Running Loss: 0.76 Running Accuracy: 73.5\n","Batch: 301 / 782 Running Loss: 0.76 Running Accuracy: 73.27\n","Batch: 401 / 782 Running Loss: 0.74 Running Accuracy: 74.07\n","Batch: 501 / 782 Running Loss: 0.72 Running Accuracy: 74.95\n","Batch: 601 / 782 Running Loss: 0.71 Running Accuracy: 75.15\n","Batch: 701 / 782 Running Loss: 0.7 Running Accuracy: 75.54\n","Training: Epoch Loss: 0.69 Epoch Accuracy: 75.94\n","--------------------------------------------------\n","Epoch No: 9\n","Batch: 1 / 782 Running Loss: 0.66 Running Accuracy: 75.0\n","Batch: 101 / 782 Running Loss: 0.72 Running Accuracy: 75.02\n","Batch: 201 / 782 Running Loss: 0.71 Running Accuracy: 75.14\n","Batch: 301 / 782 Running Loss: 0.69 Running Accuracy: 76.03\n","Batch: 401 / 782 Running Loss: 0.66 Running Accuracy: 77.23\n","Batch: 501 / 782 Running Loss: 0.63 Running Accuracy: 78.23\n","Batch: 601 / 782 Running Loss: 0.61 Running Accuracy: 78.83\n","Batch: 701 / 782 Running Loss: 0.59 Running Accuracy: 79.57\n","Training: Epoch Loss: 0.58 Epoch Accuracy: 80.03\n","--------------------------------------------------\n","Epoch No: 10\n","Batch: 1 / 782 Running Loss: 0.3 Running Accuracy: 93.75\n","Batch: 101 / 782 Running Loss: 0.51 Running Accuracy: 82.38\n","Batch: 201 / 782 Running Loss: 0.49 Running Accuracy: 83.04\n","Batch: 301 / 782 Running Loss: 0.47 Running Accuracy: 83.95\n","Batch: 401 / 782 Running Loss: 0.46 Running Accuracy: 84.36\n","Batch: 501 / 782 Running Loss: 0.45 Running Accuracy: 84.51\n","Batch: 601 / 782 Running Loss: 0.49 Running Accuracy: 83.61\n","Batch: 701 / 782 Running Loss: 0.5 Running Accuracy: 82.84\n","Training: Epoch Loss: 0.5 Epoch Accuracy: 83.13\n","--------------------------------------------------\n","Epoch No: 11\n","Batch: 1 / 782 Running Loss: 0.41 Running Accuracy: 84.38\n","Batch: 101 / 782 Running Loss: 0.38 Running Accuracy: 87.5\n","Batch: 201 / 782 Running Loss: 0.38 Running Accuracy: 87.32\n","Batch: 301 / 782 Running Loss: 0.37 Running Accuracy: 87.38\n","Batch: 401 / 782 Running Loss: 0.37 Running Accuracy: 87.58\n","Batch: 501 / 782 Running Loss: 0.36 Running Accuracy: 87.86\n","Batch: 601 / 782 Running Loss: 0.38 Running Accuracy: 87.36\n","Batch: 701 / 782 Running Loss: 0.37 Running Accuracy: 87.5\n","Training: Epoch Loss: 0.37 Epoch Accuracy: 87.63\n","--------------------------------------------------\n","Epoch No: 12\n","Batch: 1 / 782 Running Loss: 0.33 Running Accuracy: 92.19\n","Batch: 101 / 782 Running Loss: 0.33 Running Accuracy: 88.94\n","Batch: 201 / 782 Running Loss: 0.3 Running Accuracy: 89.76\n","Batch: 301 / 782 Running Loss: 0.29 Running Accuracy: 90.25\n","Batch: 401 / 782 Running Loss: 0.28 Running Accuracy: 90.7\n","Batch: 501 / 782 Running Loss: 0.27 Running Accuracy: 90.96\n","Batch: 601 / 782 Running Loss: 0.28 Running Accuracy: 90.51\n","Batch: 701 / 782 Running Loss: 0.28 Running Accuracy: 90.72\n","Training: Epoch Loss: 0.27 Epoch Accuracy: 90.91\n","--------------------------------------------------\n","Epoch No: 13\n","Batch: 1 / 782 Running Loss: 0.18 Running Accuracy: 93.75\n","Batch: 101 / 782 Running Loss: 0.22 Running Accuracy: 92.95\n","Batch: 201 / 782 Running Loss: 0.22 Running Accuracy: 92.75\n","Batch: 301 / 782 Running Loss: 0.22 Running Accuracy: 92.73\n","Batch: 401 / 782 Running Loss: 0.22 Running Accuracy: 92.62\n","Batch: 501 / 782 Running Loss: 0.22 Running Accuracy: 92.62\n","Batch: 601 / 782 Running Loss: 0.22 Running Accuracy: 92.65\n","Batch: 701 / 782 Running Loss: 0.22 Running Accuracy: 92.76\n","Training: Epoch Loss: 0.22 Epoch Accuracy: 92.79\n","--------------------------------------------------\n","Epoch No: 14\n","Batch: 1 / 782 Running Loss: 0.14 Running Accuracy: 93.75\n","Batch: 101 / 782 Running Loss: 0.18 Running Accuracy: 93.83\n","Batch: 201 / 782 Running Loss: 0.18 Running Accuracy: 93.75\n","Batch: 301 / 782 Running Loss: 0.19 Running Accuracy: 93.5\n","Batch: 401 / 782 Running Loss: 0.19 Running Accuracy: 93.55\n","Batch: 501 / 782 Running Loss: 0.19 Running Accuracy: 93.65\n","Batch: 601 / 782 Running Loss: 0.19 Running Accuracy: 93.51\n","Batch: 701 / 782 Running Loss: 0.19 Running Accuracy: 93.55\n","Training: Epoch Loss: 0.19 Epoch Accuracy: 93.55\n","--------------------------------------------------\n","Epoch No: 15\n","Batch: 1 / 782 Running Loss: 0.12 Running Accuracy: 96.88\n","Batch: 101 / 782 Running Loss: 0.18 Running Accuracy: 94.09\n","Batch: 201 / 782 Running Loss: 0.18 Running Accuracy: 93.87\n","Batch: 301 / 782 Running Loss: 0.19 Running Accuracy: 93.78\n","Batch: 401 / 782 Running Loss: 0.19 Running Accuracy: 93.61\n","Batch: 501 / 782 Running Loss: 0.19 Running Accuracy: 93.78\n","Batch: 601 / 782 Running Loss: 0.18 Running Accuracy: 93.97\n","Batch: 701 / 782 Running Loss: 0.18 Running Accuracy: 94.11\n","Training: Epoch Loss: 0.18 Epoch Accuracy: 94.12\n","--------------------------------------------------\n"]}],"source":["model=Cifar10Net_using_AlexNet()\n","model=model.to(device)\n","\n","for param in model.pretrainednet.features.parameters():\n","    param.requires_grad=False\n","\n","loss_fn=nn.CrossEntropyLoss()\n","lr=0.001\n","#optimizer=torch.optim.SGD(params=model.parameters(), lr=lr)\n","optimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\n","n_epochs=10\n","full_epochs = 15\n","for i in range(n_epochs):\n","    print(\"Epoch No:\",i+1)\n","    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,model,loss_fn,optimizer)\n","    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n","    print(\"--------------------------------------------------\")\n","\n","for param in model.pretrainednet.features.parameters():\n","    param.requires_grad=True\n","\n","for i in range(full_epochs):\n","    print(\"Epoch No:\",i+1)\n","    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,model,loss_fn,optimizer)\n","    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n","    print(\"--------------------------------------------------\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T07:42:56.092149Z","iopub.status.busy":"2024-02-24T07:42:56.091300Z","iopub.status.idle":"2024-02-24T07:59:42.562653Z","shell.execute_reply":"2024-02-24T07:59:42.561807Z","shell.execute_reply.started":"2024-02-24T07:42:56.092109Z"},"trusted":true},"outputs":[],"source":["#unpacking test images, there are 3 lacs images. This will take some time\n","shutil.unpack_archive('/kaggle/input/cifar-10/test.7z', '/kaggle/temp/')\n","\n","#unregister unpack format, we are done with it\n","shutil.unregister_unpack_format('7zip')#, ['.7z'], unpack_7zarchive)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T07:59:55.599269Z","iopub.status.busy":"2024-02-24T07:59:55.598544Z","iopub.status.idle":"2024-02-24T07:59:55.942695Z","shell.execute_reply":"2024-02-24T07:59:55.941918Z","shell.execute_reply.started":"2024-02-24T07:59:55.599238Z"},"trusted":true},"outputs":[],"source":["class TestDataset(Dataset):\n","    def __init__(self, imgpath):\n","        super().__init__()\n","        self.imgpath=imgpath\n","        _,_,self.files=next(os.walk(self.imgpath))\n","        self.length=len(self.files)\n","        self.transform=Compose([Resize((224,224), antialias=True), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])        \n","    \n","    def __len__(self):\n","        return self.length\n","    \n","    def __getitem__(self,idx):\n","        finalpath=os.path.join(self.imgpath,str(idx+1))+'.png'\n","        img=read_image(finalpath)/255.0\n","        img=self.transform(img)\n","        return img\n","\n","testdataset=TestDataset('/kaggle/temp/test/')\n","testdataloader=DataLoader(dataset=testdataset, batch_size=batch_size)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T08:00:00.649989Z","iopub.status.busy":"2024-02-24T08:00:00.649166Z","iopub.status.idle":"2024-02-24T08:00:00.657069Z","shell.execute_reply":"2024-02-24T08:00:00.656001Z","shell.execute_reply.started":"2024-02-24T08:00:00.649956Z"},"trusted":true},"outputs":[],"source":["def eval(dataloader, model,loss_fn, path):\n","    model.eval()\n","    data=pd.read_csv(path)\n","    with torch.no_grad():\n","        for i, imgs in enumerate(dataloader):\n","            finalbatchpred=np.zeros(imgs.shape[0],dtype='object')\n","            imgs=imgs.to(device)\n","            pred=model(imgs)\n","            \n","            pred=torch.argmax(pred,dim=1).type(torch.int).cpu()\n","            for j,p in enumerate(pred):\n","                finalbatchpred[j]=num2name[p.item()]\n","            data.iloc[i*batch_size:i*batch_size+batch_size ,1]=finalbatchpred\n","    \n","    data.to_csv('submission.csv', index=False)\n","    data.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T08:00:02.518787Z","iopub.status.busy":"2024-02-24T08:00:02.518417Z","iopub.status.idle":"2024-02-24T08:06:37.333036Z","shell.execute_reply":"2024-02-24T08:06:37.332245Z","shell.execute_reply.started":"2024-02-24T08:00:02.518757Z"},"trusted":true},"outputs":[],"source":["eval(testdataloader, model,loss_fn, '/kaggle/input/cifar-10/sampleSubmission.csv')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T08:08:28.527547Z","iopub.status.busy":"2024-02-24T08:08:28.526701Z","iopub.status.idle":"2024-02-24T08:08:28.619029Z","shell.execute_reply":"2024-02-24T08:08:28.618080Z","shell.execute_reply.started":"2024-02-24T08:08:28.527504Z"},"trusted":true},"outputs":[],"source":["data_gen = pd.read_csv('/kaggle/working/submission.csv')"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T08:08:37.381399Z","iopub.status.busy":"2024-02-24T08:08:37.380392Z","iopub.status.idle":"2024-02-24T08:08:37.396311Z","shell.execute_reply":"2024-02-24T08:08:37.395135Z","shell.execute_reply.started":"2024-02-24T08:08:37.381349Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["            id       label\n","0            1        bird\n","1            2    airplane\n","2            3       truck\n","3            4        ship\n","4            5    airplane\n","...        ...         ...\n","299995  299996  automobile\n","299996  299997        bird\n","299997  299998        deer\n","299998  299999         dog\n","299999  300000  automobile\n","\n","[300000 rows x 2 columns]\n"]}],"source":["print(data_gen)"]},{"cell_type":"markdown","metadata":{},"source":["If you liked the notebook, please upvote it."]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":46718,"sourceId":3649,"sourceType":"competition"}],"dockerImageVersionId":30646,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
